{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e17de769",
   "metadata": {},
   "source": [
    "# **IMPORTS**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554db043",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d84af5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import nltk\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7acbd88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd12b87",
   "metadata": {},
   "source": [
    "```\n",
    "⠀⠀⠀⠀⠀⠀⣀⣤⡤\n",
    "⠀⠀⠀⠀⢀⣾⣿⠋\n",
    "⠀⠀⠀⣠⣾⣿⡟\n",
    "⠀⠀⢸⠛⠉⢹⠃⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢀⡠⠄⠠⣀\n",
    "⠀⠀⡘⠀⠀⠀⡀⠀⠀⠀⠀⠀⠀⠀⠀⣠⠖⠉⠀⠀⠀⣾⣿⣦⡀\n",
    "⠀⠀⡇⠀⠀⠀⢡⠄⠀⠀⣀⣀⣀⣠⠊⠀⠀⠀⠀⡠⠞⠛⠛⠛⠛⡀\n",
    "⠀⠀⢃⠀⠀⠀⠀⠗⠚⠉⠉⠀⠈⠁⠀⠀⠀⢀⡔⠁⠀\n",
    "⠀⠀⠸⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⣴⣶⣄⠲⡎\n",
    "⠀⠀⠀⠃⠀⠀⢠⣤⡀⠀⠀⠀⠀⣿⣿⣿⠀⠘⡄\n",
    "⠀⠀⠀⡆⠀⠀⣿⣿⡇⠀⠀⠀⠀⠈⠛⠉⣴⣆⢹⡄\n",
    "⠀⠀⠀⣇⢰⡧⣉⡉⠀⠀⢀⡀⠀⣀⣀⣠⣿⡷⢠⡇\n",
    "⠀⠀⠀⢻⠘⠃⠈⠻⢦⠞⠋⠙⠺⠋⠉⠉⠉⢡⠟\n",
    "⠀⠀⠀⠀⠳⢄⡀⠀⠀⠀⠀⠀⠀⠀⠀⠀⢠⠋⠀⠀\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0b960c",
   "metadata": {},
   "source": [
    "# **SETTINGS**\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68eb040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib inline to visualize Matplotlib graphs\n",
    "%matplotlib inline\n",
    "\n",
    "# Configuration to set so that all the Seaborn figures come out with this size\n",
    "%config Inlinebackend.figure_format= 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4cebfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the Seaborn context to \"poster\" for larger text and figures\n",
    "sns.set_context(\"poster\")\n",
    "\n",
    "# Set the default figure size for Seaborn plots\n",
    "sns.set(rc={\"figure.figsize\": (12., 6.)})\n",
    "\n",
    "# Set the Seaborn style to \"whitegrid\" for a white background with gridlines\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44fd1c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the max displayable columns to max\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "231de6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activates XLA (for JIT compiler)\n",
    "os.environ[\"TF_XLA_FLAGS\"]= \"--tf_xla_enable_xla_devices\"\n",
    "\n",
    "# Uses the right memory when using GPU\n",
    "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"]= \"true\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607305ad",
   "metadata": {},
   "source": [
    "# **DOCUMENTATION**\n",
    "---\n",
    "\n",
    "[placeholder](https://google.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c7ec82",
   "metadata": {},
   "source": [
    "# **DATA**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc3e809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loading\n",
    "train_path= \"data/training_data.csv\"\n",
    "test_path=  \"data/testing_data.csv\"\n",
    "\n",
    "# Since the csv separates the columns with \" \" instead of a comma, we define <sep> as None\n",
    "# We use engine= \"python\" to avoid warning about \\c or \\b imports from text\n",
    "train_data=  pd.read_csv(train_path, names= [\"label\", \"text\"], header=None, sep=None, engine= \"python\")\n",
    "test_data=   pd.read_csv(test_path, names= [\"label\", \"text\"], header=None, sep=None, engine= \"python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c94aa1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿0</td>\n",
       "      <td>donald trump sends out embarrassing new year‚s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>drunk bragging trump staffer started russian c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>sheriff david clarke becomes an internet joke ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0    ﻿0  donald trump sends out embarrassing new year‚s...\n",
       "1     0  drunk bragging trump staffer started russian c...\n",
       "2     0  sheriff david clarke becomes an internet joke ..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for training creation\n",
    "df_train= pd.DataFrame(train_data)\n",
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51c6a739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>﻿2</td>\n",
       "      <td>copycat muslim terrorist arrested with assault...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>wow! chicago protester caught on camera admits...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>germany's fdp look to fill schaeuble's big shoes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text\n",
       "0    ﻿2  copycat muslim terrorist arrested with assault...\n",
       "1     2  wow! chicago protester caught on camera admits...\n",
       "2     2   germany's fdp look to fill schaeuble's big shoes"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe for testing creation\n",
    "df_test= pd.DataFrame(test_data)\n",
    "df_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8150acff",
   "metadata": {},
   "source": [
    ">`0` is real new, `1` is fake new, `2` is the prediction we need to do at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfed1e0c",
   "metadata": {},
   "source": [
    "# **DATA CHECKING**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7251b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 34152\n",
      "Columns: 2\n"
     ]
    }
   ],
   "source": [
    "# 34k rows of headers articles\n",
    "# 2 columns: text and the label.\n",
    "print(f\"Rows: {df_train.shape[0]}\\nColumns: {df_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd5fa586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label    0\n",
       "text     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a978dcc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28091</th>\n",
       "      <td>1</td>\n",
       "      <td>kerry trip to cuba for rights dialogue cancele...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "28091     1  kerry trip to cuba for rights dialogue cancele..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d3ad27",
   "metadata": {},
   "source": [
    "# **FUNCTIONS**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d26ad63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "  text= text.lower()                      # ensures lowercase\n",
    "  text= re.sub(r\"\\t\", \" \", text)          # erases \\t from text\n",
    "  text= re.sub(r\"[^a-z0-9\\s]\", \"\", text)  # erases symbols\n",
    "  text= re.sub(r\"\\s+\", \" \", text).strip() # erases initial-end blank spaces\n",
    "\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c85c47f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "  lemma= WordNetLemmatizer()                        # creates lemmatizer\n",
    "  stop_words= set(stopwords.words('english'))       # load stopwords on english\n",
    "\n",
    "  words= text.split()                               # split the text if not\n",
    "  words= [lemma.lemmatize(w) for w in words         # apply lemmatizer to all words\n",
    "           if w not in stop_words and len(w) > 2]\n",
    "  \n",
    "  return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ff2fef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model ,model_name, X_train, X_test, y_train, y_test):\n",
    "  print(f\"Training {model_name}\\n{50*\"-\"}\")\n",
    "\n",
    "  model.fit(X_train, y_train)   # fit the model\n",
    "  y_pred= model.predict(X_test) # predict with X_test\n",
    "\n",
    "  # metrics\n",
    "  print(f\"Accuracy Score: {accuracy_score(y_test, y_pred)}\")\n",
    "  print(classification_report(y_test, y_pred, target_names=[\"Fake\", \"Real\"]))\n",
    "  print(f\"Confusion Matrix:\\n{confusion_matrix(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced6265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(X, y):\n",
    "  # y is messed with '\\ufeff0' dtype\n",
    "  y= y.astype(str).str.replace(r\"[^0-9]\", \"\", regex=True).astype(int)\n",
    "\n",
    "  X_train, X_test, y_train, y_test= tts(X, y, test_size= .2, stratify= y,  random_state= 69)\n",
    "  print(f\"X-train: {X_train.shape}\\nX-test: {X_test.shape}\\ny-train: {y_train.shape}\\ny-test: {y_test.shape}\")\n",
    "  \n",
    "  return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee875787",
   "metadata": {},
   "source": [
    "#### Train/Test Split Failure\n",
    "\n",
    "**Error:**  \n",
    "`ValueError: The least populated class in y has only 1 member`\n",
    "\n",
    "**Cause:**  \n",
    "The dataset contained a hidden label (`\"﻿0\"`, BOM character) with only **one sample**.  \n",
    "`stratify` requires **at least two samples per class**, so the split failed.\n",
    "\n",
    "**Fix:**  \n",
    "Clean the labels before splitting:\n",
    "\n",
    "```python\n",
    "y = y.astype(str).str.replace(r\"[^0-9]\", \"\", regex=True).astype(int)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec4deb1",
   "metadata": {},
   "source": [
    "> this sould be on celaning data, but putting on the split_data func. is easier and quick (know as bad practice, ik)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000e808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_transform_tfidf(X_train, X_test, tfidf_vectorizer):\n",
    "  X_train_tfidf= tfidf_vectorizer.fit_transform(X_train)\n",
    "  X_test_tfidf=  tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "  print(f\"TF-IDF shape: {X_train_tfidf.shape}\")\n",
    "  return X_train_tfidf, X_test_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f26b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56da86f",
   "metadata": {},
   "source": [
    "# **DATA PRRE-PROCESSING**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6cc8c4",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "119673b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"clean_text\"]= df_train[\"text\"].apply(clean_text)\n",
    "df_train[\"lemmatized_text\"]= df_train[\"clean_text\"].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00079934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>lemmatized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3224</th>\n",
       "      <td>0</td>\n",
       "      <td>conservative calls president obama a ‚muslim‚ ...</td>\n",
       "      <td>conservative calls president obama a muslim ov...</td>\n",
       "      <td>conservative call president obama muslim resol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12263</th>\n",
       "      <td>0</td>\n",
       "      <td>the numbers are in: here‚s how the catholics v...</td>\n",
       "      <td>the numbers are in heres how the catholics vot...</td>\n",
       "      <td>number here catholic voted historic election</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18587</th>\n",
       "      <td>1</td>\n",
       "      <td>u.s. house clears path for tax bill with budge...</td>\n",
       "      <td>us house clears path for tax bill with budget ...</td>\n",
       "      <td>house clear path tax bill budget approval</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  \\\n",
       "3224      0  conservative calls president obama a ‚muslim‚ ...   \n",
       "12263     0  the numbers are in: here‚s how the catholics v...   \n",
       "18587     1  u.s. house clears path for tax bill with budge...   \n",
       "\n",
       "                                              clean_text  \\\n",
       "3224   conservative calls president obama a muslim ov...   \n",
       "12263  the numbers are in heres how the catholics vot...   \n",
       "18587  us house clears path for tax bill with budget ...   \n",
       "\n",
       "                                         lemmatized_text  \n",
       "3224   conservative call president obama muslim resol...  \n",
       "12263       number here catholic voted historic election  \n",
       "18587          house clear path tax bill budget approval  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867db75d",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a551acad",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= df_train.label\n",
    "X= df_train[\"text\"]\n",
    "X_clean= df_train[\"clean_text\"]\n",
    "X_lemma= df_train[\"lemmatized_text\"]\n",
    "# call for split_data(X, y) when requires (we're gonna do some tests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7c1aa2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X-train: (27321,)\n",
      "X-test: (6831,)\n",
      "y-train: (27321,)\n",
      "y-test: (6831,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test= split_data(X= X, y= y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b87a4698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0     17571\n",
       "1     16580\n",
       "﻿0        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f35e68",
   "metadata": {},
   "source": [
    "## **VECTORIZATION I**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ef1cff",
   "metadata": {},
   "source": [
    "We know about `BoW`, but wince `TfidfVectorizer` is just better we don't want to waste time using a method that is just worse. We'll be using directly TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3c13840f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer= TfidfVectorizer(\n",
    "  lowercase=    True,       # ensures lowercase\n",
    " #stop_words=   \"english\",  # stopwords for english lang !!! MAY WORK GRONG WITH LEMMATIZED DATA\n",
    "  max_features= 5000,       # 5000 more common words\n",
    "  ngram_range=  (1, 2),     # unigrams and bigrams\n",
    "  max_df=       .9,         # ignore words that appears more than 90% on all documents\n",
    "  min_df=       5           # ignore words that appears more than 5 times in different documents\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52c44393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF shape: (27321, 5000)\n"
     ]
    }
   ],
   "source": [
    "X_train_tfidf, X_test_tfidf= fit_transform_tfidf(X_test= X_test, X_train= X_train, tfidf_vectorizer= tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d211b6ed",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19005273",
   "metadata": {},
   "source": [
    "### Using original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4979a4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression\n",
      "--------------------------------------------------\n",
      "Accuracy Score: 0.9392475479432001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Fake       0.95      0.93      0.94      3515\n",
      "        Real       0.93      0.95      0.94      3316\n",
      "\n",
      "    accuracy                           0.94      6831\n",
      "   macro avg       0.94      0.94      0.94      6831\n",
      "weighted avg       0.94      0.94      0.94      6831\n",
      "\n",
      "Confusion Matrix:\n",
      "[[3282  233]\n",
      " [ 182 3134]]\n"
     ]
    }
   ],
   "source": [
    "lr_model= LogisticRegression(max_iter= 1000, random_state= 69)\n",
    "train_and_evaluate(lr_model, \"Logistic Regression\",  X_train_tfidf, X_test_tfidf, y_train= y_train, y_test= y_test)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
